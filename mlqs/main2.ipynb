{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "54000650-6e4d-4841-b83b-9aebfe28b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# classical models\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "\n",
    "# for the CNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c48b99f-90be-45a6-a5eb-a61c83106a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = ['walking', 'biking', 'sitting', 'stairs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "77e98a0a-9a7f-483a-ba7e-a2d1c4a11983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerometer.csv walking\n",
      "Gyroscope.csv walking\n",
      "Linear Acceleration.csv walking\n",
      "Accelerometer.csv biking\n",
      "Gyroscope.csv biking\n",
      "Linear Acceleration.csv biking\n",
      "Accelerometer.csv sitting\n",
      "Gyroscope.csv sitting\n",
      "Linear Acceleration.csv sitting\n",
      "Accelerometer.csv stairs\n",
      "Gyroscope.csv stairs\n",
      "Linear Acceleration.csv stairs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "\n",
    "SAMPLE_RATE = 60  \n",
    "window_sizes = {\n",
    "    \"walking\": 300,\n",
    "    \"running\": 300,\n",
    "    \"biking\": 300,\n",
    "    \"sitting\": 600,\n",
    "    \"stairs\": 180\n",
    "}\n",
    "#sitting, bus 600 10sec\n",
    "#walking, biking, walking 300 5sec\n",
    "#stairs 120 2sec\n",
    "\n",
    "all_sensors = {\n",
    "    \"Accelerometer.csv\": [\"Acceleration x (m/s^2)\", \"Acceleration y (m/s^2)\", \"Acceleration z (m/s^2)\"],\n",
    "    \"Gyroscope.csv\": [\"Gyroscope x (rad/s)\", \"Gyroscope y (rad/s)\", \"Gyroscope z (rad/s)\"],\n",
    "    \"Linear Acceleration.csv\": [\"Linear Acceleration x (m/s^2)\", \"Linear Acceleration y (m/s^2)\", \"Linear Acceleration z (m/s^2)\"],\n",
    "}\n",
    "\n",
    "def extract_features_from_file(file_name, axes, activity):\n",
    "    window_size = window_sizes[activity]\n",
    "    df = pd.read_csv(file_name, sep=\";\")\n",
    "    features = []\n",
    "\n",
    "    time_column = df.columns[0]  \n",
    "    time_values = df[time_column].dropna().values\n",
    "\n",
    "    for axis in axes:\n",
    "        signal = df[axis].dropna().values\n",
    "\n",
    "        for start in range(0, len(signal) - window_size, window_size):\n",
    "            segment = signal[start:start + window_size]\n",
    "            segment_time = time_values[start:start + window_size]\n",
    "\n",
    "            if len(segment) < window_size or len(segment_time) < window_size:\n",
    "                continue\n",
    "\n",
    "            row = {\n",
    "                \"sensor\": file_name,\n",
    "                \"axis\": axis,\n",
    "                \"start_time\": segment_time[0],\n",
    "                \"end_time\": segment_time[-1],\n",
    "                \"start_idx\": start,\n",
    "                \"end_idx\": start + window_size,\n",
    "                \"mean\": np.mean(segment),\n",
    "                \"std\": np.std(segment),\n",
    "                \"min\": np.min(segment),\n",
    "                \"max\": np.max(segment),\n",
    "                \"range\": np.ptp(segment),\n",
    "                \"median\": np.median(segment),\n",
    "                \"variance\": np.var(segment)\n",
    "            }\n",
    "\n",
    "            # Frequency domain\n",
    "            fft_result = fft(segment)\n",
    "            freqs = np.fft.fftfreq(len(segment), d=1 / SAMPLE_RATE)\n",
    "            amplitudes = np.abs(fft_result)\n",
    "\n",
    "            pos_mask = freqs > 0\n",
    "            freqs = freqs[pos_mask]\n",
    "            amplitudes = amplitudes[pos_mask]\n",
    "\n",
    "            if len(freqs) == 0:\n",
    "                continue\n",
    "\n",
    "            row[\"dominant_freq\"] = freqs[np.argmax(amplitudes)]\n",
    "            row[\"spectral_centroid\"] = np.sum(freqs * amplitudes) / np.sum(amplitudes)\n",
    "            # print(row)\n",
    "            features.append(row)\n",
    "\n",
    "    return features\n",
    "\n",
    "all_features = []\n",
    "root = \"./data/\"\n",
    "files = [\"Accelerometer.csv\", \"Gyroscope.csv\", \"Linear Acceleration.csv\"]\n",
    "\n",
    "for activity in activities:\n",
    "    for file in files:\n",
    "        print(file, activity)\n",
    "        axes = all_sensors[file]\n",
    "        file_features = extract_features_from_file(root + activity + \"/\" + file, axes, activity)\n",
    "        \n",
    "        for f in file_features:\n",
    "            f[\"sensor\"] = file.replace(\".csv\", \"\")\n",
    "            f[\"activity\"] = activity\n",
    "        all_features.extend(file_features)\n",
    "\n",
    "features_df = pd.DataFrame(all_features)\n",
    "features_df.to_csv(\"features_per_activity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "36aa5a85-174c-4b6c-a22a-8918812ad81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           activity_code  dominant_freq_Accelerometer_Accelerationx(m/s^2)  \\\n",
      "start_idx                                                                    \n",
      "0                      0                                          0.200000   \n",
      "0                      1                                          0.400000   \n",
      "0                      2                                          0.333333   \n",
      "0                      3                                          0.200000   \n",
      "180                    2                                          1.666667   \n",
      "\n",
      "           dominant_freq_Accelerometer_Accelerationy(m/s^2)  \\\n",
      "start_idx                                                     \n",
      "0                                                  0.200000   \n",
      "0                                                  0.100000   \n",
      "0                                                  0.333333   \n",
      "0                                                  0.200000   \n",
      "180                                                1.666667   \n",
      "\n",
      "           dominant_freq_Accelerometer_Accelerationz(m/s^2)  \\\n",
      "start_idx                                                     \n",
      "0                                                  0.200000   \n",
      "0                                                  0.100000   \n",
      "0                                                  0.333333   \n",
      "0                                                  0.200000   \n",
      "180                                                0.666667   \n",
      "\n",
      "           dominant_freq_Gyroscope_Gyroscopex(rad/s)  \\\n",
      "start_idx                                              \n",
      "0                                           2.400000   \n",
      "0                                           0.300000   \n",
      "0                                           0.333333   \n",
      "0                                           1.000000   \n",
      "180                                         0.666667   \n",
      "\n",
      "           dominant_freq_Gyroscope_Gyroscopey(rad/s)  \\\n",
      "start_idx                                              \n",
      "0                                           3.400000   \n",
      "0                                           0.600000   \n",
      "0                                           0.333333   \n",
      "0                                           0.400000   \n",
      "180                                         1.000000   \n",
      "\n",
      "           dominant_freq_Gyroscope_Gyroscopez(rad/s)  \\\n",
      "start_idx                                              \n",
      "0                                           0.200000   \n",
      "0                                           1.600000   \n",
      "0                                           0.666667   \n",
      "0                                           1.200000   \n",
      "180                                         3.333333   \n",
      "\n",
      "           dominant_freq_LinearAcceleration_LinearAccelerationx(m/s^2)  \\\n",
      "start_idx                                                                \n",
      "0                                                   5.200000             \n",
      "0                                                   2.000000             \n",
      "0                                                   3.333333             \n",
      "0                                                   1.400000             \n",
      "180                                                 1.666667             \n",
      "\n",
      "           dominant_freq_LinearAcceleration_LinearAccelerationy(m/s^2)  \\\n",
      "start_idx                                                                \n",
      "0                                                   4.400000             \n",
      "0                                                   0.100000             \n",
      "0                                                   2.000000             \n",
      "0                                                   1.200000             \n",
      "180                                                 1.666667             \n",
      "\n",
      "           dominant_freq_LinearAcceleration_LinearAccelerationz(m/s^2)  ...  \\\n",
      "start_idx                                                               ...   \n",
      "0                                                   2.000000            ...   \n",
      "0                                                   0.100000            ...   \n",
      "0                                                   6.000000            ...   \n",
      "0                                                   3.200000            ...   \n",
      "180                                                 2.333333            ...   \n",
      "\n",
      "           std_LinearAcceleration_LinearAccelerationz(m/s^2)  \\\n",
      "start_idx                                                      \n",
      "0                                                   2.200957   \n",
      "0                                                   0.078373   \n",
      "0                                                   1.978405   \n",
      "0                                                   1.928423   \n",
      "180                                                 1.597437   \n",
      "\n",
      "           variance_Accelerometer_Accelerationx(m/s^2)  \\\n",
      "start_idx                                                \n",
      "0                                            14.209136   \n",
      "0                                             0.017208   \n",
      "0                                            21.633899   \n",
      "0                                            27.437830   \n",
      "180                                           2.638658   \n",
      "\n",
      "           variance_Accelerometer_Accelerationy(m/s^2)  \\\n",
      "start_idx                                                \n",
      "0                                            15.263906   \n",
      "0                                             0.011437   \n",
      "0                                            30.104463   \n",
      "0                                            16.458535   \n",
      "180                                           7.874396   \n",
      "\n",
      "           variance_Accelerometer_Accelerationz(m/s^2)  \\\n",
      "start_idx                                                \n",
      "0                                            42.319253   \n",
      "0                                             0.013219   \n",
      "0                                            19.477829   \n",
      "0                                            20.053347   \n",
      "180                                           4.305015   \n",
      "\n",
      "           variance_Gyroscope_Gyroscopex(rad/s)  \\\n",
      "start_idx                                         \n",
      "0                                      1.151907   \n",
      "0                                      0.000619   \n",
      "0                                      1.137734   \n",
      "0                                      0.507994   \n",
      "180                                    0.881204   \n",
      "\n",
      "           variance_Gyroscope_Gyroscopey(rad/s)  \\\n",
      "start_idx                                         \n",
      "0                                      2.105408   \n",
      "0                                      0.000661   \n",
      "0                                      1.413778   \n",
      "0                                      2.038575   \n",
      "180                                    0.224669   \n",
      "\n",
      "           variance_Gyroscope_Gyroscopez(rad/s)  \\\n",
      "start_idx                                         \n",
      "0                                      1.507053   \n",
      "0                                      0.000303   \n",
      "0                                      1.010557   \n",
      "0                                      0.733300   \n",
      "180                                    0.099783   \n",
      "\n",
      "           variance_LinearAcceleration_LinearAccelerationx(m/s^2)  \\\n",
      "start_idx                                                           \n",
      "0                                                   7.144965        \n",
      "0                                                   0.006517        \n",
      "0                                                   2.967051        \n",
      "0                                                   5.624032        \n",
      "180                                                 2.556475        \n",
      "\n",
      "           variance_LinearAcceleration_LinearAccelerationy(m/s^2)  \\\n",
      "start_idx                                                           \n",
      "0                                                   5.682388        \n",
      "0                                                   0.006817        \n",
      "0                                                   4.386083        \n",
      "0                                                   1.915188        \n",
      "180                                                 7.214108        \n",
      "\n",
      "           variance_LinearAcceleration_LinearAccelerationz(m/s^2)  \n",
      "start_idx                                                          \n",
      "0                                                   4.844211       \n",
      "0                                                   0.006142       \n",
      "0                                                   3.914086       \n",
      "0                                                   3.718817       \n",
      "180                                                 2.551804       \n",
      "\n",
      "[5 rows x 82 columns]\n"
     ]
    }
   ],
   "source": [
    "df = features_df\n",
    "# 1) turn activity into codes 0–4\n",
    "df['activity_code'] = pd.Categorical(df['activity']).codes\n",
    "\n",
    "# 2) pivot sensor×axis measurements out into wide columns\n",
    "#    we keep all the statistic columns (mean, std, min, … spectral_centroid)\n",
    "stats = ['mean','std','min','max','range','median','variance','dominant_freq','spectral_centroid']\n",
    "wide = df.pivot_table(\n",
    "    index=['start_idx','activity_code'],\n",
    "    columns=['sensor','axis'],\n",
    "    values=stats\n",
    ")\n",
    "\n",
    "# 3) flatten the MultiIndex columns\n",
    "wide.columns = [\n",
    "    f\"{stat}_{sensor.replace(' ','')}_{axis.replace(' ','')}\"\n",
    "    for stat, sensor, axis in wide.columns\n",
    "]\n",
    "\n",
    "# 4) make start_idx the index, drop the old activity column\n",
    "wide = wide.reset_index().set_index('start_idx')\n",
    "\n",
    "# 5) (optional) if you want the activity_code back as a column\n",
    "#    wide = wide.reset_index().set_index('start_idx')[['activity_code'] + wide.columns.difference(['activity_code']).tolist()]\n",
    "\n",
    "# your new df:\n",
    "print(wide.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "de7e198c-b70e-4ad3-b8c2-69cd29b50049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1652\n",
      "\n",
      "Perceptron — accuracy: 0.965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98        83\n",
      "           1       0.93      0.93      0.93       122\n",
      "           2       0.97      0.96      0.96       263\n",
      "           3       0.99      0.98      0.99       182\n",
      "\n",
      "    accuracy                           0.96       650\n",
      "   macro avg       0.96      0.96      0.96       650\n",
      "weighted avg       0.96      0.96      0.96       650\n",
      "\n",
      "\n",
      "MLPClassifier — accuracy: 0.985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98        83\n",
      "           1       0.98      0.96      0.97       122\n",
      "           2       0.98      1.00      0.99       263\n",
      "           3       0.99      0.98      0.99       182\n",
      "\n",
      "    accuracy                           0.98       650\n",
      "   macro avg       0.98      0.98      0.98       650\n",
      "weighted avg       0.98      0.98      0.98       650\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/VU_HW/mlqs/venv/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 - 1s - 26ms/step - accuracy: 0.8870 - loss: 0.3567 - val_accuracy: 0.9694 - val_loss: 0.1473\n",
      "Epoch 2/10\n",
      "28/28 - 0s - 5ms/step - accuracy: 0.9555 - loss: 0.1251 - val_accuracy: 0.9694 - val_loss: 0.0932\n",
      "Epoch 3/10\n",
      "28/28 - 0s - 5ms/step - accuracy: 0.9726 - loss: 0.0751 - val_accuracy: 0.9694 - val_loss: 0.1082\n",
      "Epoch 4/10\n",
      "28/28 - 0s - 5ms/step - accuracy: 0.9886 - loss: 0.0503 - val_accuracy: 0.9898 - val_loss: 0.0443\n",
      "Epoch 5/10\n",
      "28/28 - 0s - 5ms/step - accuracy: 0.9954 - loss: 0.0291 - val_accuracy: 0.9898 - val_loss: 0.0402\n",
      "Epoch 6/10\n",
      "28/28 - 0s - 5ms/step - accuracy: 0.9977 - loss: 0.0183 - val_accuracy: 1.0000 - val_loss: 0.0247\n",
      "Epoch 7/10\n",
      "28/28 - 0s - 5ms/step - accuracy: 0.9977 - loss: 0.0118 - val_accuracy: 0.9898 - val_loss: 0.0282\n",
      "Epoch 8/10\n",
      "28/28 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 0.0176\n",
      "Epoch 9/10\n",
      "28/28 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9898 - val_loss: 0.0145\n",
      "Epoch 10/10\n",
      "28/28 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0123\n",
      "\n",
      "CNN — accuracy: 0.985\n",
      "\n",
      "SVM (RBF) — accuracy: 0.954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98        83\n",
      "           1       0.99      0.79      0.88       122\n",
      "           2       0.91      1.00      0.95       263\n",
      "           3       0.99      0.98      0.99       182\n",
      "\n",
      "    accuracy                           0.95       650\n",
      "   macro avg       0.97      0.94      0.95       650\n",
      "weighted avg       0.96      0.95      0.95       650\n",
      "\n",
      "\n",
      "kNN (k=5) — accuracy: 0.980\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        83\n",
      "           1       0.94      0.98      0.96       122\n",
      "           2       0.99      0.98      0.98       263\n",
      "           3       0.99      0.98      0.99       182\n",
      "\n",
      "    accuracy                           0.98       650\n",
      "   macro avg       0.98      0.98      0.98       650\n",
      "weighted avg       0.98      0.98      0.98       650\n",
      "\n",
      "\n",
      "Decision Tree — accuracy: 0.980\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        83\n",
      "           1       1.00      0.96      0.98       122\n",
      "           2       0.98      1.00      0.99       263\n",
      "           3       0.99      0.97      0.98       182\n",
      "\n",
      "    accuracy                           0.98       650\n",
      "   macro avg       0.98      0.98      0.98       650\n",
      "weighted avg       0.98      0.98      0.98       650\n",
      "\n",
      "\n",
      "Gaussian NB — accuracy: 0.935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95        83\n",
      "           1       0.90      0.77      0.83       122\n",
      "           2       0.90      1.00      0.95       263\n",
      "           3       0.99      0.96      0.97       182\n",
      "\n",
      "    accuracy                           0.94       650\n",
      "   macro avg       0.94      0.91      0.93       650\n",
      "weighted avg       0.94      0.94      0.93       650\n",
      "\n",
      "\n",
      "Random Forest — accuracy: 0.989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98        83\n",
      "           1       1.00      0.98      0.99       122\n",
      "           2       0.99      1.00      0.99       263\n",
      "           3       0.99      0.98      0.99       182\n",
      "\n",
      "    accuracy                           0.99       650\n",
      "   macro avg       0.99      0.99      0.99       650\n",
      "weighted avg       0.99      0.99      0.99       650\n",
      "\n",
      "\n",
      "Gradient Boosting — accuracy: 0.992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        83\n",
      "           1       0.98      0.99      0.99       122\n",
      "           2       1.00      1.00      1.00       263\n",
      "           3       0.99      0.98      0.99       182\n",
      "\n",
      "    accuracy                           0.99       650\n",
      "   macro avg       0.99      0.99      0.99       650\n",
      "weighted avg       0.99      0.99      0.99       650\n",
      "\n",
      "\n",
      "Voting Ensemble — accuracy: 0.992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        83\n",
      "           1       0.99      0.99      0.99       122\n",
      "           2       1.00      1.00      1.00       263\n",
      "           3       0.99      0.98      0.99       182\n",
      "\n",
      "    accuracy                           0.99       650\n",
      "   macro avg       0.99      0.99      0.99       650\n",
      "weighted avg       0.99      0.99      0.99       650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for the CNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense\n",
    "print(len(wide))\n",
    "# drops columns with any NaNs\n",
    "wide = wide.dropna(axis=0, how = 'any')\n",
    "\n",
    "X = wide.drop(columns='activity_code').values\n",
    "y = wide['activity_code'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=40, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# helper to fit & report\n",
    "def fit_and_report(clf, Xtr, Xte, ytr, yte, name):\n",
    "    clf.fit(Xtr, ytr)\n",
    "    ypred = clf.predict(Xte)\n",
    "    print(f\"\\n{name} — accuracy: {accuracy_score(yte, ypred):.3f}\")\n",
    "    print(classification_report(yte, ypred, zero_division=0))\n",
    "\n",
    "# 2) Perceptron\n",
    "fit_and_report(Perceptron(), X_train_scaled, X_test_scaled, y_train, y_test, \"Perceptron\")\n",
    "\n",
    "# 3) Multi-layer Perceptron\n",
    "fit_and_report(\n",
    "    MLPClassifier(hidden_layer_sizes=(100,100), max_iter=500, random_state=42),\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test,\n",
    "    \"MLPClassifier\"\n",
    ")\n",
    "\n",
    "# 4) 1D‐CNN (treat each sample as a “1×n_features” signal)\n",
    "#    reshape for Conv1D: (samples, timesteps, channels)\n",
    "Xtr_cnn = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1)\n",
    "Xte_cnn = X_test_scaled.reshape(-1, X_test_scaled.shape[1], 1)\n",
    "\n",
    "cnn = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(Xtr_cnn.shape[1],1)),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(len(np.unique(y)), activation='softmax')\n",
    "])\n",
    "cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn.fit(Xtr_cnn, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=2)\n",
    "\n",
    "loss, acc = cnn.evaluate(Xte_cnn, y_test, verbose=0)\n",
    "print(f\"\\nCNN — accuracy: {acc:.3f}\")\n",
    "\n",
    "# 5) Support Vector Machine\n",
    "fit_and_report(SVC(kernel='rbf', C=1.0), X_train_scaled, X_test_scaled, y_train, y_test, \"SVM (RBF)\")\n",
    "\n",
    "# 6) k-Nearest Neighbors\n",
    "fit_and_report(KNeighborsClassifier(n_neighbors=5), X_train_scaled, X_test_scaled, y_train, y_test, \"kNN (k=5)\")\n",
    "\n",
    "# 7) Decision Tree\n",
    "fit_and_report(DecisionTreeClassifier(max_depth=10, random_state=42),\n",
    "               X_train_scaled, X_test_scaled, y_train, y_test, \"Decision Tree\")\n",
    "\n",
    "# 8) Naive Bayes\n",
    "fit_and_report(GaussianNB(), X_train_scaled, X_test_scaled, y_train, y_test, \"Gaussian NB\")\n",
    "\n",
    "# 9) Ensembles\n",
    "# 9a) Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "# 9b) Gradient Boosting\n",
    "gb = GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "# 9c) Voting (RF + GB + MLP)\n",
    "vot = VotingClassifier([\n",
    "    ('rf', rf),\n",
    "    ('gb', gb),\n",
    "    ('mlp', MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42))\n",
    "], voting='soft')\n",
    "\n",
    "for clf, name in zip([rf, gb, vot], [\"Random Forest\", \"Gradient Boosting\", \"Voting Ensemble\"]):\n",
    "    fit_and_report(clf, X_train_scaled, X_test_scaled, y_train, y_test, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79924eb1-fddd-48e6-827e-e5442088cdd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlqs",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
